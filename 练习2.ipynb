{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算0-9的平方分别为：[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "#导入multiprocessing中的dummy方法中的Pool类\n",
    "from multiprocessing.dummy import Pool\n",
    "def calc_num2(num):\n",
    "    return num*num\n",
    "pool=Pool(3) #初始化一个有3个线程的线程池\n",
    "num_1=[x for x in range(10)]\n",
    "result=pool.map(calc_num2,num_1)  #第一个参数是执行的函数名，第二个参数是导入函数的具体参数\n",
    "print('计算0-9的平方分别为：{}'.format(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单线程循环访问100次百度首页，耗时：19.068340301513672\n",
      "5线程访问100次百度首页，耗时：5.096128463745117\n"
     ]
    }
   ],
   "source": [
    "import requests #抓取源码模块\n",
    "import time  #计时模块\n",
    "from multiprocessing.dummy import Pool\n",
    "def catching(html):\n",
    "    html_1=requests.get(html)\n",
    "    return html_1\n",
    "start=time.time()\n",
    "for i in range(100):\n",
    "    catching('http://baidu.com')\n",
    "end=time.time()\n",
    "print('单线程循环访问100次百度首页，耗时：{}'.format(end-start))\n",
    "\n",
    "start=time.time()\n",
    "u_list=[]\n",
    "for i in range(100):\n",
    "    u_list.append('http://baidu.com')\n",
    "pool=Pool(5)\n",
    "pool.map(catching,u_list)\n",
    "end=time.time()\n",
    "print('5线程访问100次百度首页，耗时：{}'.format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join函数,格式：‘sep’.join(list)\n",
    "#0s.path.join('路径1'，,'路径2')\n",
    "#输出路径为路径1\\路径2，自动用分隔符拼接好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爬取整个小说耗时：19.29182457923889\n",
      "\n",
      "小说可去代码所在目录处查看\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from multiprocessing.dummy import Pool\n",
    "start=time.time()\n",
    "start_html='https://www.kanunu8.com/book3/6879/'\n",
    "def get_html(url):  #网页源代码抓取模块\n",
    "    html = requests.get(url)\n",
    "    return html.content.decode('gbk') #这个网页需要使用gbk方式解码才能让中文正常显示\n",
    "\n",
    "def get_toc(html):  #抓取每个章节的网址模块\n",
    "    toc_block=[]\n",
    "    toc_list=[]\n",
    "    toc_html=[]\n",
    "    toc_block=re.findall('正文(.*?)</tbody>',html,re.S)\n",
    "    toc_html=re.findall('href=\"(.*?)\"',toc_block[0],re.S)  #注意有toc_block[0]，toc_html是列表\n",
    "    for ur1 in toc_html:\n",
    "        toc_list.append(start_html+ur1)\n",
    "    return toc_list\n",
    "\n",
    "def get_article(html): #抓取章节标题和内容模块\n",
    "    chapter_name=re.search('size=\"4\">(.*?)<',html,re.S).group(1)\n",
    "    text_block=re.search('<p>(.*?)</p>',html,re.S).group(1)\n",
    "    text_block=text_block.replace('<br />','')\n",
    "    return chapter_name,text_block\n",
    "def save(chapter,article):\n",
    "    os.makedirs('动物农场',exist_ok=True) #创建一个文件夹\n",
    "    with open(os.path.join('动物农场',chapter+'.txt'),'w',encoding='utf-8') as f: #写文件,目录用os模块中的path.join方法自动生成路径\n",
    "        f.write(article)                                                         #动物农场/chapter.txt\n",
    "def every_article(url):   #输入每个章节网址，抓取每个章节然后保存\n",
    "    article_html = get_html(url)\n",
    "    chapter_name, article_text = get_article(article_html)\n",
    "    save(chapter_name, article_text)\n",
    "if __name__ == '__main__':\n",
    "    toc_html = get_html(start_html)\n",
    "    toc_list = get_toc(toc_html)\n",
    "    pool = Pool(4) #线程池为4\n",
    "    pool.map(every_article, toc_list)\n",
    "end=time.time()\n",
    "print('爬取整个小说耗时：{}\\n'.format(end-start))\n",
    "print('小说可去代码所在目录处查看')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   XPath语句格式：//div[@class=\"useful\"/ul/li/text()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要的内容1\n",
      "需要的内容2\n",
      "需要的内容3\n"
     ]
    }
   ],
   "source": [
    "#XPath语句格式，书P486\n",
    "import lxml.html  #调用lxml中的html方法\n",
    "html_1='''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head lang=\"en\">\n",
    "      <meta charset=\"UTF-8\">\n",
    "      <title></title>\n",
    "</head>\n",
    "<body>\n",
    "      <div id=\"test-1\">需要的内容1</div>\n",
    "      <div id=\"test-2\">需要的内容2</div>\n",
    "      <div id=\"testfault\">需要的内容3</div>\n",
    "      <div id=\"useless\">这是我不需要的内容</div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "selector=lxml.html.fromstring(html_1)\n",
    "content=selector.xpath('//div[starts-with(@id,\"test\")]/text()') #以相同字符串开头\n",
    "for i in content:\n",
    "    print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要的内容1\n",
      "需要的内容2\n",
      "需要的内容3\n"
     ]
    }
   ],
   "source": [
    "import lxml.html  #调用lxml中的html方法\n",
    "html_2='''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head lang=\"en\">\n",
    "      <meta charset=\"UTF-8\">\n",
    "      <title></title>\n",
    "</head>\n",
    "<body>\n",
    "      <div id=\"abc-key\">需要的内容1</div>\n",
    "      <div id=\"123-key-000\">需要的内容2</div>\n",
    "      <div id=\"haha-key\">需要的内容3</div>\n",
    "      <div id=\"useless\">这是我不需要的内容</div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "selector=lxml.html.fromstring(html_2)\n",
    "content_1=selector.xpath('//div[contains(@id,\"-key\")]/text()')  #属性值包含相同字段\n",
    "for i in content_1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['需要的内容1', '需要的内容2', '需要的内容3']\n"
     ]
    }
   ],
   "source": [
    "import lxml.html  #调用lxml中的html方法\n",
    "html_3='''\n",
    "<html>\n",
    "      <head lang=\"en\">\n",
    "      <meta charset=\"UTF-8\">\n",
    "      <title></title>\n",
    " </head>\n",
    " <body>\n",
    "      <div class=\"useful\">\n",
    "        <ul>\n",
    "         <li class=\"info\">需要的内容1</li>\n",
    "         <li class=\"info\">需要的内容2</li>\n",
    "         <li class=\"info\">需要的内容3</li>\n",
    "        </ul>\n",
    "      </div>\n",
    "      <div class=\"useless\">\n",
    "        <ul>\n",
    "         <li class=\"info\">垃圾1</li> \n",
    "         <li class=\"info\">垃圾2</li> \n",
    "        </ul>\n",
    "      </div> \n",
    " </body>\n",
    " </html>\n",
    "'''\n",
    "selector=lxml.html.fromstring(html_3)\n",
    "content_2=selector.xpath('//div[@class=\"useful\"]')\n",
    "content_3=content_2[0].xpath('ul/li/text()') #先抓大再抓小，子xpath开头不需要添斜线\n",
    "print(content_3)                             #[0]含义是先取div结点内内容，再xpath抓取里面内容\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          我左青龙，\n",
      "\n",
      "     \n",
      "              右白虎，\n",
      "              上朱雀，\n",
      "                  下玄武。\n",
      "              \n",
      "              老牛在当中，\n",
      "          \n",
      "          龙头在胸口。\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "html3='''\n",
    "<! DOCTYPE html>\n",
    "    <html>\n",
    "    <head lang=\"en\">\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>标题</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div id=\"test3\">\n",
    "          我左青龙，\n",
    "\n",
    "     <span id=\"tiger\">\n",
    "              右白虎，\n",
    "              <ul>上朱雀，\n",
    "                  <li>下玄武。</li>\n",
    "              </ul>\n",
    "              老牛在当中，\n",
    "          </span>\n",
    "          龙头在胸口。\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "'''\n",
    "selector=lxml.html.fromstring(html3)\n",
    "p=selector.xpath('//div[@id=\"test3\"]') #只获取这个结点，不获取里面的东西\n",
    "content_4=p[0].xpath('string(.)')\n",
    "print(content_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真的受不了郑爽演技\n",
      "有多少人为了一直都能做朋友而迟迟不敢迈出那一步......\n",
      "哭不出来用纸遮\n",
      "顾森湘的父母是不是傻？\n",
      "有人看了吗？？结局是什么。。。？？？求告知\n",
      "大结局还算圆满，他们还是在一起了\n",
      "郝甜和杜度怎么那么傻！有没有人和我一样超级讨厌这俩\n",
      "感觉越来越讨厌电视剧的易瑶了，演的真的很讨厌，反而觉得唐小米\n",
      "我要给编剧寄红包！！！！！\n",
      "求遥铭续写，好想看啊\n",
      "齐铭的一声老婆，甜晕了😀😀😀😘😘\n",
      "睡前再次感叹一句，流淌的美好时光真的是一部好剧#流淌的美好时\n",
      "求问每次郝湉出场的背景纯音乐钢琴曲是什么歌？\n",
      "流淌的美好时光\n",
      "流淌的美好时光续写{祝易瑶齐铭}\n",
      "流淌的没好时光\n",
      "流淌的美好时光1-51集整理好了 有需要的评论自取哦～\n",
      "求流淌的美好时光全集资源\n",
      "流淌的美好时光1-51集整理好了  有需要的评论自取哦～\n",
      "流淌的美好时光1-51集 大家有需要的评论自取呀～\n",
      "流淌的美好时光\n",
      "话说唐小米什么时候才会被揭穿？齐铭什么时候才知道唐小米对易遥\n",
      "流淌的美好时光  好看  真有意思。\n",
      "剧本写作技巧？剧本怎么写？\n",
      "这部电视最让我意难平的不是唐小米做不做牢，也不是顾森湘的死而\n",
      "如果不喜欢可以别看这部剧啊，觉得演技不好的你们可以拒绝，可以\n",
      "看完电视剧的吧有，我想问一下，骆荀到底和谁在一起了？谢谢，万\n",
      "**自有天收\n",
      "以小的亏损，赌大的利益。\n",
      "有没有哪个大神有大结局资源，红包看，不想等了\n",
      "如果天宇和郑爽真的在一起该有多好呀……\n",
      "我恋爱了🙈\n",
      "有没有哪位大神知道齐铭当时唱的英文歌是哪首？有知道的能不能告\n",
      "看了第一集，郑爽和马天宇说话口齿不清，听得很难受，郑爽更严重\n",
      "顾森湘死了，齐铭和易遥肯定都会自责，他们还能坦然地在一起吗？\n",
      "电视剧里易遥怀孕了吗？\n",
      "看预告，感觉要还原原著了，心疼我易遥\n",
      "顾森湘是自杀了吗？还是？\n",
      "唐小米真坏\n",
      "今天看了一个觉得很有意思的电视剧，好像是叫流淌的美好时光，当\n",
      "是该分手冷静一下了——不过，不是齐铭的错\n",
      "电视剧里面齐铭是不是没喜欢过顾森湘啊\n",
      "对于齐名父亲这种明知道小三是贪自己的钱为什么还非要离婚和小三\n",
      "不一样的“湘湘”，同样的雅君（湘湘扮演者）喜欢湘湘或者雅君的\n",
      "郑爽的演技真是太尴尬了，她妈死了那里\n",
      "武汉工程科技学院欢迎你，爱了爱了\n",
      "奇迹看似遥不可及，但只有我们付出努力，那看似不可能发生的奇迹\n",
      "小爽和天宇哥好友夫妻相，哈哈\n"
     ]
    }
   ],
   "source": [
    "#利用Google浏览器爬贴吧数据\n",
    "import requests\n",
    "import lxml.html\n",
    "ul=requests.get(\"https://tieba.baidu.com/f?kw=%E6%B5%81%E6%B7%8C%E7%9A%84%E7%BE%8E%E5%A5%BD%E6%97%B6%E5%85%89\").content.decode()\n",
    "selector=lxml.html.fromstring(ul)\n",
    "p=selector.xpath('//li[@class=\" j_thread_list clearfix\"]/div[@class=\"t_con cleafix\"]/div[@class=\"col2_right j_threadlist_li_right \"]/div[@class=\"threadlist_lz clearfix\"]/div[@class=\"threadlist_title pull_left j_th_tit \"]/a/text()')\n",
    "\n",
    "for i in p:\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import lxml.html\n",
    "url=requests.get('https://www.damai.cn/projectlist.do').content.decode()\n",
    "selector=lxml.html.fromstring(url)\n",
    "item_list=selector.xpath('//div[2]/div[2]/div[1]/div[3]/div[1]/div/div[2]')\n",
    "item_dict_list=[]\n",
    "for item in item_list:\n",
    "    show_name=item.xpath('div[@class=\"items__txt\"]/div[@class=\"items__txt__title\"]/a/text()')\n",
    "    show_place=item.xpath('div[@class=\"items__txt\"]/div[@class=\"items__txt__time\"]/a[@class=\"items__txt__venue__icon\"]/text()')\n",
    "    show_time=item.xpath('div[@class=\"items__txt\"]/div[@class=\"items__txt__time\"]/a[@class=\"items__txt__time__icon\"]/text()')\n",
    "    show_price=item.xpath('div[@class=\"items__txt\"]/div[@class=\"items__txt__price\"]/span/text()')\n",
    "\n",
    "    item_dict = {'show_name': show_name[0] if show_name else '',\n",
    "                 'show_description': show_description[0] if show_description else '',\n",
    "                 'show_time': show_time[0].strip() if show_time else '',\n",
    "                 'show_place': show_place[0] if show_place else '',\n",
    "                 'show_price': show_price[0] if show_price else ''}\n",
    "    item_dict_list.append(item_dict)\n",
    "print(item_list)\n",
    "with open('result.csv','w',encoding='utf-8') as f:\n",
    "    writer=csv.DictWriter(f,fieldnames=['show name','show place','show time','show price'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(item_dict_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo service mongod start\n",
    "#sudo service mongod restart\n",
    "#sudo service mongod stop\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client=MongoClient()\n",
    "#第一种方式初始化数据库\n",
    "database=client.Chapter6  #创建数据库名称\n",
    "collection=database.spider #创建数据表名称\n",
    "\n",
    "#第二种方式\n",
    "database=client['Chapter6']\n",
    "collention=database['spider']\n",
    "\n",
    "#方式二常用，处理批量数据时使用\n",
    "database_name_list=['db1','db2','db3','db4']\n",
    "for each_db in database_name_list:\n",
    "    db=client[each_db]\n",
    "    collection=db.test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tzy/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectId('5d43fe12238d5c7be8a2621c')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#先在终端输入命令启动mongo:sudo service mongod start\n",
    "#ps -ef | grep mongod   检查是否启动成功\n",
    "#sudo service mongod stop\n",
    "from pymongo import MongoClient\n",
    "client_1=MongoClient()\n",
    "database=client_1['ku_1']\n",
    "collection=database['spider']\n",
    "data={'id':112233,'name':'znn','age':21,'salary':'888'}\n",
    "collection.insert(data) #插入字典数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tzy/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ObjectId('5d44390c238d5c7be8a26223'),\n",
       " ObjectId('5d44390c238d5c7be8a26224'),\n",
       " ObjectId('5d44390c238d5c7be8a26225')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_data=[{'id':11,'name':'znn1','age':21,'salary':'888'},{'id':22,'name':'tzy1','age':21,'salary':'000'},{'id':33,'name':'txy1','age':22,'salary':'111'}]\n",
    "database_1=client_1['ku_2']\n",
    "collection_1=database_1['spider']\n",
    "collection_1.insert(more_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('5d4429fe238d5c7be8a26220'),\n",
       "  'id': 11,\n",
       "  'name': 'znn',\n",
       "  'age': 21,\n",
       "  'salary': '888'},\n",
       " {'_id': ObjectId('5d4429fe238d5c7be8a26221'),\n",
       "  'id': 22,\n",
       "  'name': 'tzy',\n",
       "  'age': 21,\n",
       "  'salary': '000'},\n",
       " {'_id': ObjectId('5d4429fe238d5c7be8a26222'),\n",
       "  'id': 33,\n",
       "  'name': 'txy',\n",
       "  'age': 21,\n",
       "  'salary': '111'},\n",
       " {'_id': ObjectId('5d44390c238d5c7be8a26223'),\n",
       "  'id': 11,\n",
       "  'name': 'znn1',\n",
       "  'age': 21,\n",
       "  'salary': '888'},\n",
       " {'_id': ObjectId('5d44390c238d5c7be8a26224'),\n",
       "  'id': 22,\n",
       "  'name': 'tzy1',\n",
       "  'age': 21,\n",
       "  'salary': '000'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#普通查找\n",
    "#find(筛选条件，选择返回哪些key)\n",
    "content=[x for x in collection_1.find({'age':21})] #返回年龄都为21的数据\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'txy', 'age': 21}, {'name': 'txy1', 'age': 22}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content=[x for x in collection_1.find({'salary':'111'},{'_id':0,'name':1,'age':1})] #第一个参数是返回年龄都为21的数据，第二个参数，0为不返回，1为返回该关键词\n",
    "content                                                                           #不写出的字段默认不返回，_id比较特殊，必须指定0或1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "降序\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('5d4429fe238d5c7be8a26220'),\n",
       "  'id': 11,\n",
       "  'name': 'znn',\n",
       "  'age': 21,\n",
       "  'salary': '888'},\n",
       " {'_id': ObjectId('5d44390c238d5c7be8a26223'),\n",
       "  'id': 11,\n",
       "  'name': 'znn1',\n",
       "  'age': 21,\n",
       "  'salary': '888'},\n",
       " {'_id': ObjectId('5d4429fe238d5c7be8a26222'),\n",
       "  'id': 33,\n",
       "  'name': 'txy',\n",
       "  'age': 21,\n",
       "  'salary': '111'},\n",
       " {'_id': ObjectId('5d4429fe238d5c7be8a26221'),\n",
       "  'id': 22,\n",
       "  'name': 'tzy',\n",
       "  'age': 21,\n",
       "  'salary': '000'},\n",
       " {'_id': ObjectId('5d44390c238d5c7be8a26224'),\n",
       "  'id': 22,\n",
       "  'name': 'tzy1',\n",
       "  'age': 21,\n",
       "  'salary': '000'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#逻辑查询\n",
    "#    $gt 大于 $lt 小于 $gte 大于等于  $lte 小于等于  $eq 等于   $ ne 不等于\n",
    "content=[x for x in collection_1.find({'age':{'$gt':20,'$lt':22}}).sort('salary',1)] #sort方法，1为升序，-1为降序\n",
    "content\n",
    "print('降序\\t')\n",
    "content=[x for x in collection_1.find({'age':{'$gt':20,'$lt':22}}).sort('salary',-1)] #sort方法，1为升序，-1为降序\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 22]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update_one({'要修改的关键词':  },{'$set':{'修改成的关键词':}}) 第一个参数可以用逻辑查询\n",
    "# update_many({'要修改的关键词':  },{'$set':{'修改成的关键词':}}) 第一个参数可以用逻辑查询\n",
    "collection_1.update_many({'age':21},{'$set':{'age':30}})  #21岁都修改为30岁\n",
    "collection_1.delete_many({'age':22}) #删除\n",
    "content=[x for x in collection_1.distinct('age')] #返回一个去重后的年龄的列表\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'123', b'123', b'123', b'123', b'123', b'123', b'123', b'123']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 启动redis需要在终端输入redis-cli\n",
    "#用redis—py操作redis\n",
    "#本地redis\n",
    "import redis\n",
    "client=redis.StrictRedis()\n",
    "#列表左侧添加数据用lpush,左侧用l，右侧用r\n",
    "client.lpush('chapter_6',123)\n",
    "client.llen('chapter_6') #算长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'123',\n",
       " b'123',\n",
       " b'123',\n",
       " b'123',\n",
       " b'123',\n",
       " b'123',\n",
       " b'123',\n",
       " b'123',\n",
       " b'4',\n",
       " b'3',\n",
       " b'2',\n",
       " b'1',\n",
       " b'world',\n",
       " b'hello']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.lrange('chapter_6',0,15) #读取列表0-15数据\n",
    "# lpop 从列表右侧读一个值，读取后删除该数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MongoDB与Redis的使用。其中，MongoDB主要用来存放爬虫爬到的各种需要持久化保存的数据，\n",
    "#而Redis则用来存放各种中间数据。通过减少频繁读/写MongoDB，用Redis来弥补MongoDB的一些不足，可以显著提高爬虫的运行效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.sadd('test_set','www.baidu.com')  #集合中添加一个网址\n",
    "# spop是从集合中读取一个值，然后删去\n",
    "# scard 查看集合的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #爬虫1将每个章节的网址全部爬取到redis上\n",
    "import redis\n",
    "from lxml import html\n",
    "client=redis.StrictRedis()\n",
    "source=requests.get('http://dongyeguiwu.zuopinj.com/5525').content\n",
    "selector=html.fromstring(source)\n",
    "url_list=selector.xpath('//div[@class=\"book_list\"]/ul/li/a/@href') # @href这样的方式可以提取出href后面的章节网址链接\n",
    "for url in url_list:\n",
    "    client.lpush('url_queue',url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7ffb2d4fa5c8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import redis\n",
    "import lxml.html\n",
    "import pymongo\n",
    "client=redis.StrictRedis()\n",
    "connection=pymongo.MongoClient()\n",
    "db=connection.chapter_6\n",
    "handler=db.white\n",
    "\n",
    "connection_list=[]\n",
    "while client.llen('url_queue')>0:\n",
    "    url=client.lpop('url_queue').decode() #读取redis中储存的每一章网址数据\n",
    "    source=requests.get(url).content      #抓取每个章节源码\n",
    "    selector=lxml.html.fromstring(source)\n",
    "    chapter_name=selector.xpath('//div[@class=\"h1title\"]/h1/text()')[0] #章节标题\n",
    "    content=selector.xpath('//div[@id=\"htmlContent\"]/p/text()')         #章节内容\n",
    "    connection_list.append({'title':chapter_name,'content':'\\n'.join(content)})\n",
    "handler.insert_many(connection_list)  # insert_one  insert_many 用法不同\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
